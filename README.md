# âš½ Soca Scores - MLOps Pipeline




## First Article in the Series : [ Phase 0: Setting up the Development Environment](https://medium.com/p/1960fb160e30)
## Second Article in the Series :[ Phase 1: Data Ingestion](https://medium.com/data-ai-and-beyond/building-a-full-stack-mlops-system-predicting-the-2025-2026-english-premier-league-season-phase-c9c1d4f83187)
## Third Article in the Series :[ Phase 2: Data Cleaning and Transformation](https://medium.com/data-ai-and-beyond/building-a-full-stack-mlops-system-predicting-the-2025-2026-english-premier-league-season-phase-8760a79ddfe1)

[Data Project Structure Best Practices](https://medium.com/the-pythonworld/best-practices-for-structuring-a-python-project-like-a-pro-be6013821168)


> **A comprehensive machine learning operations (MLOps) project for predicting English Premier League match outcomes using historical data and advanced feature engineering.**

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://python.org)
[![MLOps](https://img.shields.io/badge/MLOps-Enabled-green)](https://ml-ops.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-Dashboard-red)](https://streamlit.io)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---
To run python -m src. components.<module.py>
Please note that some workflows and/or tools might be added or deleted at my discretion as per my needs.


## ðŸŽ¯ **Project Overview**
![alt text](image.png)<br />

This project implements a comprehensive MLOps pipeline for predicting Premier League match outcomes, including win/loss/draw probabilities, as well as goal predictions. Built with production-ready practices, the system ingests data from footballdata.uk, processes historical match data, engineers meaningful features, trains predictive models, and serves predictions through an interactive Streamlit dashboard.

### **ðŸ† Key Features**
- **Automated Data Ingestion** from footballdata.uk
- **Database Storage** through a serverless PostgreSQL DB
- **Feature Store** for managing engineered features
- **Model Registry** with versioning and experiment tracking
- **Real-time Predictions** via Streamlit dashboard
- **MLOps Best Practices** with CI/CD, monitoring, and automated retraining
- **Modular Architecture** allowing independent component execution

---

## ðŸš€ **Approach & Methodology**

### **ðŸ”„ My MLOps Lifecycle approach**
```
Data Ingestion â†’ Data Cleaning,Transformation and DB Loading â†’ EDA -> Feature Engineering and Feature Store Storage â†’ Model Training â†’ Evaluation â†’ Deployment â†’ Monitoring
        â†‘                                                                                                                                                              â†“
        â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â† **Continuous Improvement Loop** â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†
```

### **ðŸ“Š Data Strategy**
- **Source**: Historical Premier League data from footballdata.UK (CSV format)
- **Scope**: Multiple seasons of match data with team statistics
- **Updates**: Weekly ingestion during active season
- **Quality**: Automated validation and cleaning pipelines

### **ðŸ¤– Machine Learning Approach**
- **Problem Type**: Multi-class classification (Win/Draw/Loss) + Regression (Goal prediction - optional or future consideration)
- **Feature Engineering**: Team form, head-to-head records, player statistics, seasonal trends
- **Model Selection**: Ensemble methods with hyperparameter optimization
- **Evaluation**: Cross-validation with time-series split for temporal data

### **ðŸ—ï¸ MLOps Architecture**
- **Orchestration**: Pipeline automation for data processing and model training
- **Feature Store**: Centralized feature management with versioning
- **Model Registry**: Automated model versioning and promotion
- **Monitoring**: Data drift detection and model performance tracking
- **Deployment**: Containerized applications with CI/CD integration

---

## ðŸ“ **Expected Project Structure (Might Change as per needed requirements)** 

```
premier_league_predictions/  
â”‚
â”œâ”€â”€ ðŸ“Š data/                        # Data storage layers
â”‚   â”œâ”€â”€ common_data/                        # Raw CSV files from footballdata.uk containing URLs and any other common usable data
â”‚   â”œâ”€â”€ ingested_data/                      # Merged datasets
â”‚   â”œâ”€â”€ cleaned_data/                       # Cleaned datasets for DB loading
â”‚   â””â”€â”€ feature_store_data/                 # Transformed feature stores
|   â””â”€â”€ predictions/                        # Model predictions output
â”‚
â”œâ”€â”€ ðŸ§ª experiments/                 # ML experimentation workspace
â”‚   â”œâ”€â”€ notebooks/                  # Jupyter notebooks for EDA
â”‚   â”œâ”€â”€ scripts/                    # Experimental scripts
â”‚   â””â”€â”€ results/                    # Experiment outputs and metrics
â”‚
â”œâ”€â”€ ðŸ”§ src/                         # Core application modules
â”‚   â”œâ”€â”€ data_ingestion/             # Data collection and validation
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py       # â­ Main ingestion script
â”‚   â”‚   â”œâ”€â”€ data_validator.py       # Data quality checks
â”‚   â”‚   â””â”€â”€ data_merger.py          # CSV merging logic
â”‚   â”‚
â”‚   â”œâ”€â”€ feature_store/              # Feature engineering pipeline
â”‚   â”‚   â”œâ”€â”€ feature_engineering.py  # Feature creation
â”‚   â”‚   â”œâ”€â”€ feature_store.py        # Feature storage & retrieval
â”‚   â”‚   â””â”€â”€ feature_validator.py    # Feature quality assurance
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                     # ML model management
â”‚   â”‚   â”œâ”€â”€ training.py             # â­ Model training script
â”‚   â”‚   â”œâ”€â”€ inference.py            # Prediction generation
â”‚   â”‚   â”œâ”€â”€ model_registry.py       # Model versioning
â”‚   â”‚   â””â”€â”€ evaluation.py           # Performance evaluation
â”‚   â”‚
â”‚   â”œâ”€â”€ monitoring/                 # MLOps monitoring
â”‚   â”‚   â”œâ”€â”€ data_drift.py           # Data drift detection
â”‚   â”‚   â”œâ”€â”€ model_drift.py          # Model performance monitoring
â”‚   â”‚   â””â”€â”€ alerts.py               # Alerting system
â”‚   â”‚
â”‚   â””â”€â”€ utils/                      # Shared utilities
â”‚       â”œâ”€â”€ config.py               # Configuration management
â”‚       â”œâ”€â”€ logger.py               # Logging utilities
â”‚       â””â”€â”€ database.py             # Database connections
â”‚
â”œâ”€â”€ ðŸš€ deployment/                  # Application deployment
â”‚   â”œâ”€â”€ streamlit_app/              # Interactive dashboard
â”‚   â”œâ”€â”€ api/                        # REST API (optional)
â”‚   â””â”€â”€ docker/                     # Containerization
â”‚
â”œâ”€â”€ ðŸ”„ pipelines/                   # Orchestration scripts
â”‚   â”œâ”€â”€ data_pipeline.py            # End-to-end data processing
â”‚   â”œâ”€â”€ training_pipeline.py        # Model training pipeline
â”‚   â””â”€â”€ inference_pipeline.py       # Prediction pipeline
â”‚
â”œâ”€â”€ âš™ï¸ configs/                     # Configuration files
â”‚   â”œâ”€â”€ data_config.yaml            # Data ingestion parameters
â”‚   â”œâ”€â”€ model_config.yaml           # ML model configurations
â”‚   â””â”€â”€ app_config.yaml             # Application settings
â”‚
â”œâ”€â”€ ðŸ§ª tests/                       # Comprehensive testing
â”‚   â”œâ”€â”€ unit/                       # Unit tests
â”‚   â”œâ”€â”€ integration/                # Integration tests
â”‚   â””â”€â”€ fixtures/                   # Test data
â”‚
â””â”€â”€ logger
â””â”€â”€ logger

```

## ðŸ“ **Current Project Structure** 
```

Directory structure:
â””â”€â”€ jnyambok-soca-scores/
    â”œâ”€â”€ README.md
    â”œâ”€â”€ data_dictionary_spreadsheet.html  #Added a html page for the data_dictionary
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ logs/
    â”œâ”€â”€ datasets/
    â”‚   â””â”€â”€ common_data/
    â”‚       â”œâ”€â”€ english_league_data_urls.csv
    â”‚       â””â”€â”€ feature_catalog.csv
    â”œâ”€â”€ experiments/
    â”‚   â”œâ”€â”€ notebooks/
    â”‚   â”‚   â””â”€â”€ data_ingestion.ipynb
    â”‚   â””â”€â”€ scripts/             #Added a scripts environ to test scripts
    â”‚       â””â”€â”€ data_cleaning.py
    â””â”€â”€ src/
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ exception.py
        â”œâ”€â”€ logger.py
        â””â”€â”€ components/
            â”œâ”€â”€ __init__.py
            â”œâ”€â”€ data_cleaning.py       #Added a script for cleaning the data before the database
            â”œâ”€â”€ data_ingestion.py    
            â””â”€â”€ database_scripts/
                â””â”€â”€ db_creation_and_initial_insertion.py  #For the initial creation and insertion

```

---

## ðŸ› ï¸ **Technology Stack**

| Component | Technology | Purpose |
|-----------|------------|---------|
| **Data Processing** | `pandas`, `numpy` | Data manipulation and analysis |
| **Machine Learning** | `scikit-learn` | Model training and evaluation |
| **Feature Store** | `Feast` / Custom | Feature management and serving |
| **Database** | `NEON DB` | Data persistence |
| **Orchestration** | `Apache Airflow`, `Prefect` | Pipeline automation |
| **Experiment Tracking** | `MLflow` | Model versioning and tracking |
| **Frontend** | `Streamlit` | Interactive dashboard |
| **API** | `FastAPI` | REST API services |
| **Containerization** | `Docker` | Application packaging |
| **CI/CD** | `GitHub Actions` | Automated deployment |
| **Monitoring** | `Grafana`, `Prometheus` | System and model monitoring |

---

## ðŸš€ **Quick Start**

### **Prerequisites**
- Python 3.8+
- PostgreSQL (optional, SQLite for local development)
- Docker (for containerized deployment)

### **Installation**
```bash
# Clone the repository
git clone https://github.com/yourusername/premier_league_predictions.git
cd premier_league_predictions

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### **Run Individual Components**
```bash
# Data ingestion
python -m src.data_ingestion.data_ingestion

# Feature engineering
python -m src.feature_store.feature_engineering

# Model training
python -m src.models.training

# Generate predictions
python -m src.models.inference

# Start Streamlit dashboard
streamlit run deployment/streamlit_app/app.py
```

### **Run Complete Pipeline**
```bash
# Execute full MLOps pipeline
python scripts/run_full_pipeline.py
```

---

## ðŸ“Š **Model Performance Goals**

### **Target Metrics**
- **Match Outcome Accuracy**: >55% (industry benchmark ~52%)
- **Goal Prediction MAE**: <1.2 goals per match
- **Confidence Calibration**: Well-calibrated probability predictions

### **Business Value**
- Provide insights for football analytics
- Support betting strategy research (educational purposes)
- Demonstrate MLOps best practices in sports analytics



## ðŸ“ˆ **Roadmap**

### **Phase 1: Data Ingestion** âœ… (Finished on 08/19)
- [x] Project structure and configuration
- [x] Loading dataset urls
- [x] Ingesting data from data sources (footballdata.uk)
- [x] Merging the various datasets and storing locally

### **Phase 2: Data Cleaning x Transformation and Database Loading**
- [ ] Feature store implementation
- [ ] Model registry setup
- [ ] Streamlit dashboard
- [ ] Basic monitoring

### **Phase 3: Advanced Features** ðŸ“‹
- [ ] Advanced feature engineering (player data, weather)
- [ ] Model ensemble and optimization
- [ ] Real-time prediction API
- [ ] Comprehensive monitoring dashboard

### **Phase 4: Production** ðŸš€
- [ ] Cloud deployment
- [ ] Automated CI/CD
- [ ] Performance optimization
- [ ] User feedback integration

---

## ðŸ¤ **Contributing**

Contributions are welcome! Please read our [Contributing Guidelines](CONTRIBUTING.md) for details on our code of conduct and the process for submitting pull requests.

### **Development Workflow**
1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ðŸ“„ **License**

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ðŸŽ¯ **Acknowledgments**

- **footballdata.uk** for providing comprehensive historical match data
- **Premier League** for the exciting matches that make this project possible
- **Open Source Community** for the amazing tools and libraries

---


*Built with â¤ï¸ for football analytics and MLOps excellence*
